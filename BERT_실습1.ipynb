{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPyTOdzafv23zlfQh9iAtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46819be41eed425da057552e812b4594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b47f4fe94a6948a69bf65c4a29ce9fb9",
              "IPY_MODEL_b42613b0dff24c8b892835c0d02e9a5f",
              "IPY_MODEL_07e2b8d7e46f48f38fe4b3de8891bca3"
            ],
            "layout": "IPY_MODEL_0036dcee49ca4ec7b91fd5588ade91d3"
          }
        },
        "b47f4fe94a6948a69bf65c4a29ce9fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099d921d015c41f4b30f1a23793bcbce",
            "placeholder": "​",
            "style": "IPY_MODEL_42736c9489e642a99b5ca002b576e39b",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "b42613b0dff24c8b892835c0d02e9a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306f44fe20e7421fa1b4c67194e75768",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9295a4acc04741bcbf0fb2a0e1889423",
            "value": 714290682
          }
        },
        "07e2b8d7e46f48f38fe4b3de8891bca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8187d822ccee430c923d49200c37fe10",
            "placeholder": "​",
            "style": "IPY_MODEL_91800f4eac7347368cec9d8a31129a6b",
            "value": " 714M/714M [00:14&lt;00:00, 49.2MB/s]"
          }
        },
        "0036dcee49ca4ec7b91fd5588ade91d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "099d921d015c41f4b30f1a23793bcbce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42736c9489e642a99b5ca002b576e39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306f44fe20e7421fa1b4c67194e75768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9295a4acc04741bcbf0fb2a0e1889423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8187d822ccee430c923d49200c37fe10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91800f4eac7347368cec9d8a31129a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91a3febc45f345f5982fd943aa0ca3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda1d5f1b7084ad1899469bddb3d8c8b",
              "IPY_MODEL_eb955ae023c54a7d8b94955de5ee25cb",
              "IPY_MODEL_7b777bdbb5e64afb80cd45ea4b225402"
            ],
            "layout": "IPY_MODEL_4e1f72c2a229431a9adc003ea4b75605"
          }
        },
        "eda1d5f1b7084ad1899469bddb3d8c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66425b33a1ca4817bef310cce3c35269",
            "placeholder": "​",
            "style": "IPY_MODEL_e9806fac34ba475089b376c6066894c0",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "eb955ae023c54a7d8b94955de5ee25cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63d2cacb80348f493e89dbd1f4e3bd5",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f36d12e42614b298af6f06b83210961",
            "value": 714314041
          }
        },
        "7b777bdbb5e64afb80cd45ea4b225402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d070d6865ca426d8a15fa106f5947d9",
            "placeholder": "​",
            "style": "IPY_MODEL_1b357bdcffe94bb5964439d5db9856a4",
            "value": " 714M/714M [00:14&lt;00:00, 68.2MB/s]"
          }
        },
        "4e1f72c2a229431a9adc003ea4b75605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66425b33a1ca4817bef310cce3c35269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9806fac34ba475089b376c6066894c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d63d2cacb80348f493e89dbd1f4e3bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f36d12e42614b298af6f06b83210961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d070d6865ca426d8a15fa106f5947d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b357bdcffe94bb5964439d5db9856a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UiinKim/UiinKim/blob/main/BERT_%EC%8B%A4%EC%8A%B51.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. TPU 설정"
      ],
      "metadata": {
        "id": "DvnB6wKl8bov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeN4CcJj5yHd",
        "outputId": "4718d130-3f06-4d8e-bf92-e3d12dca2331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.21.53.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x79158ab935e0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "#TPU 초기화\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "resolver=tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TPU Strategy 세팅\n",
        "strategy=tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "CqI_udrG6RFF"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#딥러닝 모델 컴파일\n",
        "#모델의 컴파일은 strategy.scope 내에서 이루어져야 한다. crate_model()과 같은 함수를 만들어 strategy.scope 내에서 해당 함수를 호출하여 모델을 컴파일한다.\n",
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "      [\n",
        "          tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28,28,1)),\n",
        "          tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(256, activation='relu'),\n",
        "          tf.keras.layers.Dense(128,activation='relu'),\n",
        "          tf.keras.layers.Dense(10)\n",
        "      ]\n",
        "  )"
      ],
      "metadata": {
        "id": "dsashBne6aWQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with strategy.scope()에 create_model()함수를 호출하여 모델을 컴파일한다.\n",
        "with strategy.scope():\n",
        "  model=create_model()\n",
        "  model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "ObP_74tQ7kek"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Transformer 모델 클래스 불러오기"
      ],
      "metadata": {
        "id": "ktm20DC18fHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6cNGwrD9gxK",
        "outputId": "aeb109b2-ee91-4433-ce1f-48a17aa319c9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다 대 일 유형(many-to-one)\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "#model=TFBertForSequencesClassification.from_pretrained('모델 이름', num_labels=분류할 레이블 개수)\n"
      ],
      "metadata": {
        "id": "9QLcId5s7-vH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#다 대 다 유형(many-to-many)\n",
        "from transformers import TFBertForTokenClassification\n",
        "\n",
        "#model=TFBertForTokenClassification.from_pretrained(\"모델 이름\", num_labels=분류할 레이블 개수)\n"
      ],
      "metadata": {
        "id": "uFVz3t_W9yHa"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#질의 응답 유형\n",
        "from transformers import TFBertForQuestionAnswering\n",
        "\n",
        "#model=TFBertForQuestionAnswering.from_pretrained('모델 이름')\n"
      ],
      "metadata": {
        "id": "QZPG0b7Y9_Wa"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n-wNklcm-NLS",
        "outputId": "efcb3f9f-f6b6-40a4-d393-27aefc569c9a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.31.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "metadata": {
        "id": "sUkJ3C35-gQO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWMSE9y_AhTz",
        "outputId": "31f53926-c361-4733-d18f-08e5fe55435a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x79158ab93070>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_table('ratings_train.txt')\n",
        "test_data=pd.read_table('ratings_test.txt')"
      ],
      "metadata": {
        "id": "AySbalZeED7L"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train 데이터 개수 : \", len(train_data))\n",
        "print(\"test 데이터 개수 : \", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPLh7T2GELcj",
        "outputId": "92405e2d-5307-4458-e6f8-b1f9c2738f8f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 데이터 개수 :  150000\n",
            "test 데이터 개수 :  50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTMq5_ZZETBr",
        "outputId": "41b7e94a-353c-4be2-daa4-4b7da3697c70"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150000 entries, 0 to 149999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        150000 non-null  int64 \n",
            " 1   document  149995 non-null  object\n",
            " 2   label     150000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe7U0K6JFJbJ",
        "outputId": "042b4bec-1e32-44c4-a6e4-8609e3558101"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        50000 non-null  int64 \n",
            " 1   document  49997 non-null  object\n",
            " 2   label     50000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.dropna(how='any')\n",
        "test_data=test_data.dropna(how='any')\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxyvc9qpFNEC",
        "outputId": "6c80ecce-1175-49f4-f8d8-636073a1664d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149995\n",
            "49997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "id": "qH4GmuQdF7hF"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 정수 인코딩\n",
        "print(tokenizer.encode('보는 내내 그대로 들어맞는 예측 카리스마 없는 악역'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B7k5-PMHRn2",
        "outputId": "0389cae0-5707-4d75-86dd-cf22ff0ebd96"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9356, 11018, 8996, 31605, 110589, 71568, 118913, 11018, 9576, 119281, 9786, 79940, 23811, 40364, 9520, 23160, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 토큰화\n",
        "print(tokenizer.tokenize(\"보는 내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmJR9fF3dJTH",
        "outputId": "5464ec2d-2bc0-40b9-84d2-fc471d99411d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['보', '##는', '내', '##내', '그대로', '들어', '##맞', '##는', '예', '##측', '카', '##리스', '##마', '없는', '악', '##역']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인코드 후 디코드\n",
        "print(tokenizer.decode(tokenizer.encode(\"보는 내내 그대로 들어맞는 예측 카리스마 없는 악역\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhs6_L-_dQGc",
        "outputId": "88abeaac-f30c-41a7-800d-9d7e1a968f56"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 보는 내내 그대로 들어맞는 예측 카리스마 없는 악역 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for elem in tokenizer.encode(\"보는 내내 그대로 들어맞는 예측 카리스마 없는 악역\"):\n",
        "  print(tokenizer.decode(elem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd4DXKFhg4hv",
        "outputId": "45101406-1451-418f-ae9e-28ddaa726623"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ C L S ]\n",
            "보\n",
            "# # 는\n",
            "내\n",
            "# # 내\n",
            "그 대 로\n",
            "들 어\n",
            "# # 맞\n",
            "# # 는\n",
            "예\n",
            "# # 측\n",
            "카\n",
            "# # 리 스\n",
            "# # 마\n",
            "없 는\n",
            "악\n",
            "# # 역\n",
            "[ S E P ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CLS와 SEP의 코드번호\n",
        "print(tokenizer.decode(101))\n",
        "print(tokenizer.decode(102))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DRTtTfTiZn7",
        "outputId": "d4703ebd-83ff-4751-e9e6-5cfcea988c10"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ C L S ]\n",
            "[ S E P ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
        "print(tokenizer.sep_token, ':', tokenizer.sep_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYvYiHQ4ivXq",
        "outputId": "06fb603c-c604-4f2a-dde2-08172642941d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] : 101\n",
            "[SEP] : 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.pad_token, ':', tokenizer.pad_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gwFKDuajEgT",
        "outputId": "cb6d6cd1-4ecf-43cb-fbbf-3b34f0c06b7e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PAD] : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#문장의 최대 길이 설정\n",
        "max_seq_len=128"
      ],
      "metadata": {
        "id": "muIYdAP-jTLL"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#128까지 패딩\n",
        "encoded_result=tokenizer.encode(\"전율을 일으키는 영화, 다시 보고싶은 영화\", max_length=max_seq_len, pad_to_max_length=True)\n",
        "print(encoded_result)\n",
        "print(\"길이 : \", len(encoded_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eprp2zT1paTU",
        "outputId": "a6ffda2b-dc15-4575-bbf8-c2ffa7b2db03"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 117, 25805, 98199, 119088, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "길이 :  128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#세그먼트 인풋\n",
        "print([0]*max_seq_len) #최대 길이만큼 0으로 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4urvf4UqtOy",
        "outputId": "24260ee8-c12e-46ea-aa8c-c7fa29c84aa5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#마스크 인풋\n",
        "valid_num=len(tokenizer.encode(\"전율을 일으키는 영화, 다시 보고싶은 영화\"))\n",
        "print(valid_num*[1]+(max_seq_len-valid_num)*[0]) #문장의 의미가 담긴 만큼 1 나머지는 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pscEoZ4GpoET",
        "outputId": "b9a8813c-6faf-46d2-ad1a-eb1e839d2c9a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
        "  input_ids, attention_masks, token_type_ids, data_labels=[],[],[],[]\n",
        "\n",
        "  for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "       # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
        "       input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
        "\n",
        "       # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
        "       padding_count = input_id.count(tokenizer.pad_token_id)\n",
        "       attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
        "\n",
        "       # token_type_id는 세그먼트 임베딩을 위한 것으로 이번 예제는 문장이 1개이므로 전부 0으로 통일.\n",
        "       token_type_id = [0] * max_seq_len\n",
        "       assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "       assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
        "       assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
        "\n",
        "       input_ids.append(input_id)\n",
        "       attention_masks.append(attention_mask)\n",
        "       token_type_ids.append(token_type_id)\n",
        "       data_labels.append(label)\n",
        "\n",
        "  input_ids=np.array(input_ids, dtype=int)\n",
        "  attention_masks=np.array(attention_masks, dtype=int)\n",
        "  token_type_ids=np.array(token_type_ids, dtype=int)\n",
        "\n",
        "  data_labels=np.asarray(data_labels, dtype=np.int32)\n",
        "\n",
        "  return (input_ids, attention_masks, token_type_ids), data_labels"
      ],
      "metadata": {
        "id": "XkISa9WNp7gs"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y=convert_examples_to_features(train_data['document'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alJW-4yo2hHO",
        "outputId": "78173989-7a73-4b47-9bca-6b697d9e208a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149995/149995 [01:18<00:00, 1922.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X, test_y=convert_examples_to_features(test_data['document'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlrHOcvz3yRz",
        "outputId": "8e578a29-c00c-4a34-d329-82c3067c1f2f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/49997 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 49997/49997 [00:37<00:00, 1339.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_length:128\n",
        "input_id=train_X[0][0]\n",
        "attention_mask=train_X[1][0]\n",
        "token_type_id=train_X[2][0]\n",
        "label=train_y[0]\n",
        "\n",
        "print('단어에 대한 정수 인코딩 : ', input_id)\n",
        "print('어텐션 마스크 : ', attention_mask)\n",
        "print(\"세그먼트 인코딩 : \", token_type_id)\n",
        "print('각 인코딩의 길이 : ', len(input_id))\n",
        "print('정수 인코딩 복원 : ', tokenizer.decode(input_id))\n",
        "print('레이블 : ', label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agv5yE4XBEjD",
        "outputId": "3ef0f1b4-6d2f-4ea7-ef51-9553dce4b487"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어에 대한 정수 인코딩 :  [   101   9519   9074 119005    119    119   9708 119235   9715 119230\n",
            "  16439  77884  48549   9284  22333  12692    102      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0]\n",
            "어텐션 마스크 :  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "세그먼트 인코딩 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "각 인코딩의 길이 :  128\n",
            "정수 인코딩 복원 :  [CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "레이블 :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=TFBertModel.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "46819be41eed425da057552e812b4594",
            "b47f4fe94a6948a69bf65c4a29ce9fb9",
            "b42613b0dff24c8b892835c0d02e9a5f",
            "07e2b8d7e46f48f38fe4b3de8891bca3",
            "0036dcee49ca4ec7b91fd5588ade91d3",
            "099d921d015c41f4b30f1a23793bcbce",
            "42736c9489e642a99b5ca002b576e39b",
            "306f44fe20e7421fa1b4c67194e75768",
            "9295a4acc04741bcbf0fb2a0e1889423",
            "8187d822ccee430c923d49200c37fe10",
            "91800f4eac7347368cec9d8a31129a6b"
          ]
        },
        "id": "TMu2Jm2rBoAM",
        "outputId": "e5a44537-a085-4451-8fbf-e2c4fe1c211c"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46819be41eed425da057552e812b4594"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len=128"
      ],
      "metadata": {
        "id": "Tuzi9hirBv10"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_layer=tf.keras.layers.Input(shape=(max_seq_len,),dtype=tf.int32)\n",
        "attention_masks_layer=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n",
        "token_type_ids_layer=tf.keras.layers.Input(shape=(max_seq_len, ),dtype=tf.int32)\n",
        "\n",
        "outputs=model([input_ids_layer, attention_masks_layer, token_type_ids_layer])"
      ],
      "metadata": {
        "id": "_oFeUdtlByAz"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MotwEsNCQFl",
        "outputId": "eab79b96-d41e-4289-c931-8a609d8fae92"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES-2wz_lCaVM",
        "outputId": "14153ec9-4f38-471a-a28f-3ed27b24c67c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uah0Ug4MCenD",
        "outputId": "f5ddcb56-7a98-465a-9628-c9eb876f45e6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TFBertForSequenceClassification(tf.keras.Model):\n",
        "  def __init__(self, model_name):\n",
        "    super(TFBertForSequenceClassification, self).__init__()\n",
        "    self.bert=TFBertModel.from_pretrained(model_name, from_pt=True)\n",
        "    self.classifier=tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02), activation='sigmoid', name='classifier')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    input_ids, attention_mask, token_type_ids=inputs\n",
        "    outputs=self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    cls_token=outputs[1]\n",
        "    prediction=self.classifier(cls_token)\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "1sc_0jEECgIU"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TPU 작동코드\n",
        "resolver=tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://'+os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHwtROOTDS3U",
        "outputId": "be19ad8f-8cc4-485a-a48e-f2d126245a63"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.21.53.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x791581c61180>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy=tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPQOMpSgDod8",
        "outputId": "1005cdab-ed01-4034-f950-853e1fab1e45"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model=TFBertForSequenceClassification('bert-base-multilingual-cased')\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "  loss=tf.keras.losses.BinaryCrossentropy()\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "91a3febc45f345f5982fd943aa0ca3a8",
            "eda1d5f1b7084ad1899469bddb3d8c8b",
            "eb955ae023c54a7d8b94955de5ee25cb",
            "7b777bdbb5e64afb80cd45ea4b225402",
            "4e1f72c2a229431a9adc003ea4b75605",
            "66425b33a1ca4817bef310cce3c35269",
            "e9806fac34ba475089b376c6066894c0",
            "d63d2cacb80348f493e89dbd1f4e3bd5",
            "8f36d12e42614b298af6f06b83210961",
            "3d070d6865ca426d8a15fa106f5947d9",
            "1b357bdcffe94bb5964439d5db9856a4"
          ]
        },
        "id": "VjBgL7RfDupT",
        "outputId": "25e05c74-0acd-4266-cd0b-4e9e7de4a811"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91a3febc45f345f5982fd943aa0ca3a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_y, epochs=2, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z00zURdpD0_X",
        "outputId": "07dacad7-b93e-423e-fe8a-c463770054f8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 359s 134ms/step - loss: 0.3971 - accuracy: 0.8153 - val_loss: 0.3365 - val_accuracy: 0.8573\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 227s 121ms/step - loss: 0.3042 - accuracy: 0.8685 - val_loss: 0.3115 - val_accuracy: 0.8677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79158a76dd80>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.evaluate(test_X, test_y, batch_size=1024)\n",
        "print('test loss, test acc: ', results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyQUOAZTEWgb",
        "outputId": "078af762-5b34-43ce-a217-0654033e47ab"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 23s 332ms/step - loss: 0.3198 - accuracy: 0.8606\n",
            "test loss, test acc:  [0.3197639584541321, 0.8605916500091553]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  input_id=tokenizer.encode(new_sentence, max_length=max_seq_len, pad_to_max_length=True)\n",
        "\n",
        "  padding_count=input_id.count(tokenizer.pad_token_id)\n",
        "  attention_mask=[1]*(max_seq_len-padding_count)+[0]*padding_count\n",
        "  token_type_id=[0]*max_seq_len\n",
        "\n",
        "  input_ids=np.array([input_id])\n",
        "  attention_masks=np.array([attention_mask])\n",
        "  token_type_ids=np.array([token_type_id])\n",
        "\n",
        "  encoded_input=[input_ids, attention_masks, token_type_ids]\n",
        "  score=model.predict(encoded_input)[0][0]\n",
        "  print(score)\n",
        "\n",
        "  if(score>0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score*100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1-score)*100))\n"
      ],
      "metadata": {
        "id": "kZLshG8hEhWD"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict(\"보던거라 계속 보고 있었는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인 모습에\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFarT-GcHlac",
        "outputId": "4c3b661e-0c4d-43c0-d506-7e2d7df2918e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 16s 16s/step\n",
            "0.0101059675\n",
            "98.99% 확률로 부정 리뷰입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('스토리는 확실히 실망이였지만 배우들 연기력이 대박이었다. 특히 이제훈 연기는 정말... 이  배우들로 이렇게밖에 만들지 못한 영화는 아쉽지만 배우들 연기력과 사운드는 정말 빛났던 영화. 기대하고 극장에서 보면 많이 실망했겠지만 평점보고 기대없이 집에서 편하게 보면 괜찮아요. 이제훈님 연기력은 최고인 것 같습니다 ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgWi67I1Hq3m",
        "outputId": "1f61e923-deaa-4a3b-ced2-e5e96f08d74a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 861ms/step\n",
            "0.98332304\n",
            "98.33% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('이 영화 존잼입니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8nna2XwH5wG",
        "outputId": "33de993b-7a30-4811-b59a-df02af70011f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "0.59670216\n",
            "59.67% 확률로 긍정 리뷰입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWuhqNkaH9sr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}