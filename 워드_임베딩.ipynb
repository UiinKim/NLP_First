{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcR5f1Bt8nGWCW1awWGmfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UiinKim/UiinKim/blob/main/%EC%9B%8C%EB%93%9C_%EC%9E%84%EB%B2%A0%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pXhi--gGair1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 다운로드\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename='ted_en-20160408.xml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruuNa1viAbiF",
        "outputId": "1e445ea7-9cac-4e38-b6ed-7981055a9be6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x79040c3afe80>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THaiVPhnFxhv",
        "outputId": "1888f652-858d-460e-901d-030cef81dad5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF-8')\n",
        "target_text=etree.parse(targetXML) #Xml파일 간단하게 파싱\n",
        "\n",
        "# xml 파일로부터 <content>와 </content>사이의 내용만 가져온다.\n",
        "parse_text='\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "#정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text) #괄호로 구성된 내용을 제거\n",
        "\n",
        "#입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행\n",
        "sent_text=sent_tokenize(content_text)\n",
        "\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환\n",
        "normalized_text=[]\n",
        "for string in sent_text:\n",
        "  tokens=re.sub(r\"[^a-z0-9]+\",\" \",string.lower()) #sentence.lower() 상태에서 a-z0-9가 아닌 것들은 모두 ' '으로 바꾼다.\n",
        "  normalized_text.append(tokens)\n",
        "\n",
        "result=[word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "metadata": {
        "id": "dhLF4HE9Ao-n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf5GXJ2xFvPx",
        "outputId": "433f8113-1dbd-4785-889e-dbe544578699"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 273424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in result[:3]:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHjKLMP6Gk-X",
        "outputId": "ac1cee71-61fb-4142-99c2-1e7d6e62b164"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2Vec 학습시키기\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model=Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "#vector_size는 데이터가 적을 땐 크게, 데이터가 많을 땐 작게(150~300)\n",
        "#window는 훈련시 앞 뒤로 고려하는 단어의 개수\n",
        "#min_count는 해당 빈도수보다 적게 등장할 경우 모델 학습에서 배제\n",
        "#worker은 스레드 개수. 스레드가 많아질수록 빌드 속도가 빨라진다.(본인 컴퓨터 스펙에 맞게 쓴다.)\n",
        "#sg 0=CBOW(중심단어 예측) 1=Skipgram(주변단어 예측)"
      ],
      "metadata": {
        "id": "F6Msg08VIBsH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_result=model.wv.most_similar('man')\n",
        "#Word2Vec는 입력한 'man'에 대해서 가장 유사한 단어들을 출력해주는 기능이다.\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3kc8t8GZ2h2",
        "outputId": "eff8f4c6-77c9-4b0a-978e-1c465691cd29"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8416481614112854), ('guy', 0.8075767755508423), ('lady', 0.7642030119895935), ('boy', 0.758362352848053), ('girl', 0.7405058145523071), ('gentleman', 0.7271239757537842), ('poet', 0.6821939945220947), ('kid', 0.6817570924758911), ('soldier', 0.6721681356430054), ('friend', 0.6577139496803284)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxHr7C9WaChC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}