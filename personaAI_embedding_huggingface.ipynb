{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPg2HdoH8o2p"
      },
      "source": [
        "# Getting Started With Embeddings: Notebook Companion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N6a-RPS9jLg"
      },
      "source": [
        "![](/../assets/80_getting_started_with_embeddings/thumbnail.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70e0sP4t-Cvx"
      },
      "source": [
        "## 1. Embedding a dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_McQCASzpT_"
      },
      "outputs": [],
      "source": [
        "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "hf_token = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23fNFAm1h24M"
      },
      "source": [
        "The first time you generate the embeddings it may take a while (approximately 20 seconds) for the API to return them. We use the `retry` decorator (install with `pip install retry`) so that if on the first try `output = query(dict(inputs = texts))` doesn't work, wait 10 seconds and try again three times. The reason this happens is because on the first request, the model needs to be downloaded and installed in the server, but subsequent calls are much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvEXtWmsgK2B"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install retry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg0HaYGSz2GC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from retry import retry\n",
        "\n",
        "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
        "headers = {\"Authorization\": f\"Bearer {hf_token}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DStL7NC_h1J0"
      },
      "outputs": [],
      "source": [
        "@retry(tries=3, delay=10)\n",
        "def query(texts):\n",
        "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts})\n",
        "    result = response.json()\n",
        "    if isinstance(result, list):\n",
        "      return result\n",
        "    elif list(result.keys())[0] == \"error\":\n",
        "      raise RuntimeError(\n",
        "          \"The model is currently loading, please re-run the query.\"\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7iHNzsq05k7"
      },
      "outputs": [],
      "source": [
        "texts = [\"How do I get a replacement Medicare card?\",\n",
        "        \"What is the monthly premium for Medicare Part B?\",\n",
        "        \"How do I terminate my Medicare Part B (medical insurance)?\",\n",
        "        \"How do I sign up for Medicare?\",\n",
        "        \"Can I sign up for Medicare Part B if I am working and have health insurance through an employer?\",\n",
        "        \"How do I sign up for Medicare Part B if I already have Part A?\",\n",
        "        \"What are Medicare late enrollment penalties?\",\n",
        "        \"What is Medicare and who can get it?\",\n",
        "        \"How can I get help with my Medicare Part A and Part B premiums?\",\n",
        "        \"What are the different parts of Medicare?\",\n",
        "        \"Will my Medicare premiums be higher because of my higher income?\",\n",
        "        \"What is TRICARE ?\",\n",
        "        \"Should I sign up for Medicare Part B if I have Veteransâ€™ Benefits?\"]\n",
        "\n",
        "output = query(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVDIE076NIZB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "embeddings = pd.DataFrame(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElAxRHyzjrd4"
      },
      "outputs": [],
      "source": [
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKJJzhYX-OEA"
      },
      "source": [
        "## 2. Host embeddings for free on the Hugging Face Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGQ0g9DM2wn_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk9el6S52qZl",
        "outputId": "7db49001-d878-4812-8d8e-d119809259b7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: "
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z06NVe-83wf1"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli repo create embedded_faqs_medicare --type dataset --organization ITESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beO4nEln40-N"
      },
      "outputs": [],
      "source": [
        "# This is code required to install git-lfs however it already is installed in Colab instances.\n",
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O0b5awa4uTd"
      },
      "outputs": [],
      "source": [
        "git clone https://{rladmldls@gmail.com}:{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}@huggingface.co/datasets/ITESM/embedded_faqs_medicare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSVebbDq6n4g"
      },
      "outputs": [],
      "source": [
        "embeddings.to_csv(\"embedded_faqs_medicare/embeddings.csv\", index=False)\n",
        "print(embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iezsa2P38rie"
      },
      "source": [
        "Changing directory to our repo `embedded_faqs_medicare`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU2t0vL18gJw"
      },
      "outputs": [],
      "source": [
        "%cd embedded_faqs_medicare/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZFTmNB_7BJu"
      },
      "outputs": [],
      "source": [
        "!git lfs track *.csv\n",
        "!git add .gitattributes\n",
        "!git add embeddings.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kDcX1lb9xWP"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"your email here\"\n",
        "!git config --global user.name \"your git user here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMsNtanX8yOj"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"First version of the embedded_faqs_medicare dataset\"\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azsWjRb9-gZY"
      },
      "source": [
        "## 3. Get the most similar Frequently Asked Questions to a query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miTP1yro5Xnq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_kc0dbl5H9d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "faqs_embeddings = load_dataset('ITESM/embedded_faqs_medicare')\n",
        "dataset_embeddings = torch.from_numpy(faqs_embeddings[\"train\"].to_pandas().to_numpy()).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb5yJd7ABUBG"
      },
      "outputs": [],
      "source": [
        "question = [\"How can Medicare help me?\"]\n",
        "output = query(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3TBXYhi3sof"
      },
      "outputs": [],
      "source": [
        "query_embeddings = torch.FloatTensor(output)\n",
        "print(f\"The size of our embedded dataset is {dataset_embeddings.shape} and of our embedded query is {query_embeddings.shape}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwVWBV8i4ldh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHlOjB-17zKk"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.util import semantic_search\n",
        "\n",
        "hits = semantic_search(query_embeddings, dataset_embeddings, top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P2poeGiecM6"
      },
      "outputs": [],
      "source": [
        "[texts[hits[0][i]['corpus_id']] for i in range(len(hits[0]))]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Notebook Companion: Embedding-as-a-Service.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}