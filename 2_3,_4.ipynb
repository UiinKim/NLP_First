{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnUtCTi5pDWOqlaUXsEBej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UiinKim/NLP_First/blob/main/2_3%2C_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "통계기반기법(배치) <-> 추론기반기법(미니배치)\n",
        "gpu를 사용해서 병렬로 들어감 -> 학습속도 향상\n",
        "\n"
      ],
      "metadata": {
        "id": "SBrnHPAZSdv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 context 정보를 입력받아 각 단어의 출현 확률을 출력"
      ],
      "metadata": {
        "id": "UDTD50FhY1V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MatMul:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)] #grads에 기울기 W보관하기 위해 리스트 선언\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        W, = self.params\n",
        "        out = np.matmul(x, W)\n",
        "        self.x = x\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        W, = self.params\n",
        "        dx = np.matmul(dout, W.T) #x이므로 W.T와 dout\n",
        "        dW = np.matmul(self.x.T, dout) #W이므로 x.T와 dout\n",
        "        self.grads[0][...] = dW #역전파가 된 기울기를 grads에 보관\n",
        "        #생략기호 ...을 활용하여 덮어쓰기 수행 -> 메모리 주소 고정된 자리에 복사(리스트이기 때문에 중요)\n",
        "        return dx"
      ],
      "metadata": {
        "id": "S9oOwCM5hmhO"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnA96Pd-urvX",
        "outputId": "376962f4-db9c-4b98-eed8-1145ca867c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.09621656 2.03090481 0.76253725]]\n"
          ]
        }
      ],
      "source": [
        "#원핫벡터 사용\n",
        "#각 단어 벡터들은 fully connected layer로 연결\n",
        "import numpy as np\n",
        "\n",
        "c=np.array([[1, 0, 0, 0, 0, 0, 0]]) #input\n",
        "W=np.random.randn(7, 3) #weight\n",
        "h=np.matmul(c, W) #hidden node\n",
        "print(h)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "W=np.random.randn(7, 3)\n",
        "layer=MatMul(W)\n",
        "h=layer.forward(c)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrGPVVXObqEY",
        "outputId": "199ddf36-238f-4334-f685-0bacb85ddd62"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.21663523 0.99500705 1.91426609]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CBOW 모델 추론 과정\n",
        "\n",
        "c0=np.array([[1,0,0,0,0,0,0]])\n",
        "c1=np.array([[0,0,1,0,0,0,0]])\n",
        "\n",
        "W_in=np.random.randn(7, 3)\n",
        "W_out=np.random.randn(3, 7)\n",
        "\n",
        "in_layer0=MatMul(W_in) #c0과 가중치 연결\n",
        "in_layer1=MatMul(W_in) #c1과 가중치 연결\n",
        "out_layer=MatMul(W_out)\n",
        "\n",
        "h0=in_layer0.forward(c0)\n",
        "h1=in_layer1.forward(c1)\n",
        "h=0.5*(h0+h1)\n",
        "s=out_layer.forward(h)\n",
        "\n",
        "print(s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdwNvGknhq2b",
        "outputId": "a517ff55-3589-4dbe-b2c5-886d9df25bcd"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.47101459 -0.2605173   1.84899944  0.69576521 -0.08741238  0.70320076\n",
            "   0.02843392]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "context를 신경망에 넣으면 target이 나오도록"
      ],
      "metadata": {
        "id": "pCuJEXgPuwKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text=text.lower()\n",
        "  text=text.replace('.', ' .')\n",
        "  words=text.split()\n",
        "  word_to_id={}\n",
        "  id_to_word={}\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id=len(word_to_id)\n",
        "      word_to_id[word]=new_id\n",
        "      id_to_word[new_id]=word\n",
        "\n",
        "  corpus=np.array([word_to_id[w]for w in words])\n",
        "  return corpus, word_to_id, id_to_word"
      ],
      "metadata": {
        "id": "hk_xX-otpmBf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text='You say goodbye and I say hello. '\n",
        "corpus, word_to_id, id_to_word=preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(id_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbfHA5Izvh4m",
        "outputId": "c206f8a4-0449-495b-eea9-73ee4292e0ae"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context와 target 만드는 함수\n",
        "def create_contexts_target(corpus, window_size=1):\n",
        "  target=corpus[window_size:-window_size] #여기서는 맨 앞 단어와 맨 뒷 단어 제외 windowsize=1이기 때문\n",
        "  contexts=[]\n",
        "\n",
        "  for idx in range(window_size, len(corpus)-window_size):#맨 앞과 맨 뒤 단어 제외하고 반복\n",
        "    cs=[] #context 저장\n",
        "    for t in range(-window_size, window_size+1): #해당 인덱스의 -1, +1까지 고려\n",
        "      if t==0: #0일 경우는 target 본인이기 때문에 제외\n",
        "        continue\n",
        "      cs.append(corpus[idx+t]) #양 옆의 단어들을 context에 저장\n",
        "    contexts.append(cs) #context 모음에 해당 context 저장\n",
        "\n",
        "  return np.array(contexts), np.array(target)"
      ],
      "metadata": {
        "id": "dKRpWE_YvqfA"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts, target=create_contexts_target(corpus)\n",
        "\n",
        "print(contexts)\n",
        "\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUPt7wpgw-Cr",
        "outputId": "0d2214d5-91c3-4f73-8d70-8347459a5f59"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_one_hot(corpus, vocab_size):\n",
        "  N=corpus.shape[0] #target의 shape을 복사\n",
        "\n",
        "  if corpus.ndim==1: #target이 1차원인 경우\n",
        "    one_hot=np.zeros((N, vocab_size), dtype=np.int32)#one-hot으로 만들기 위해 target, vocab_size로 0행렬 생성\n",
        "    for idx, word_id in enumerate(corpus): #해당 target의 좌표 생성\n",
        "      one_hot[idx, word_id]=1 #해당 target의 자표에 1 입력하여 one-hot vector 생성\n",
        "\n",
        "  elif corpus.ndim==2: #target이 2차원인 경우\n",
        "    C=corpus.shape[1] #target의 다음 차원의 형태를 C에 저장\n",
        "    one_hot=np.zeros((N, C, vocab_size), dtype= np.int32) #target[0], target[1], vocabsize로 0행렬ㄹ 생성\n",
        "    for idx_0, word_ids in enumerate(corpus):\n",
        "      for idx_1, word_id in enumerate(word_ids):\n",
        "        one_hot[idx_0, idx_1, word_id]=1\n",
        "\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "tSx5q5EgT6qV"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "vocab_size = len(word_to_id)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)"
      ],
      "metadata": {
        "id": "BceutqFZxLZh"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBOW 구현"
      ],
      "metadata": {
        "id": "9wOj1SFbaxqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "tZHYKjHrbyGX"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "Jfoei4fcb4ml"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.out = softmax(x)\n",
        "        return self.out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = self.out * dout\n",
        "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
        "        dx -= self.out * sumdx\n",
        "        return dx"
      ],
      "metadata": {
        "id": "e2X0WXJBb1D7"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.y = None  # softmax의 출력\n",
        "        self.t = None  # 정답 레이블\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        # 정답 레이블이 원핫 벡터일 경우 정답의 인덱스로 변환\n",
        "        if self.t.size == self.y.size:\n",
        "            self.t = self.t.argmax(axis=1)\n",
        "\n",
        "        loss = cross_entropy_error(self.y, self.t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = self.y.copy()\n",
        "        dx[np.arange(batch_size), self.t] -= 1\n",
        "        dx *= dout\n",
        "        dx = dx / batch_size\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "w6eBNVd2bnbq"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCBOW:\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    V, H=vocab_size, hidden_size\n",
        "\n",
        "    #가중치 초기화\n",
        "    W_in=0.01*np.random.randn(V, H).astype('f') #vocab_size, hidden_size 차원의 난수 생성\n",
        "    W_out=0.01*np.random.randn(H, V).astype('f') #\n",
        "\n",
        "    #계층 생성\n",
        "    self.in_layer0=MatMul(W_in) #연결층1\n",
        "    self.in_layer1=MatMul(W_in) #연결층2\n",
        "    self.out_layer=MatMul(W_out) #합해져서 나오는 층\n",
        "    self.loss_layer=SoftmaxWithLoss() #손실층\n",
        "\n",
        "    #모든 가중치와 기울기를 리스트에 모은다.\n",
        "    layers=[self.in_layer0, self.in_layer1, self.out_layer]\n",
        "    self.params, self.grads=[],[]\n",
        "    for layer in layers: #모든 층의 각 층마다의 파라미터와 기울기를 저장\n",
        "      self.params+=layer.params\n",
        "      self.grads+=layer.grads\n",
        "\n",
        "    #인스턴스 변수에 단어의 분산 표현을 저장\n",
        "    self.word_vecs=W_in\n",
        "\n",
        "  def forward(self, contexts, target):\n",
        "    h0=self.in_layer0.forward(contexts[:,0])\n",
        "    h1=self.in_layer1.forward(contexts[:,1])\n",
        "    h=(h0+h1)*0.5\n",
        "    score=self.out_layer.forward(h)\n",
        "    loss=self.loss_layer.forward(score, target)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    ds=self.loss_layer.backward(dout)\n",
        "    da=self.out_layer.backward(ds)\n",
        "    da*=0.5\n",
        "    self.in_layer1.backward(da)\n",
        "    self.in_layer0.backward(da)\n",
        "    return None\n",
        "\n"
      ],
      "metadata": {
        "id": "8MQekJNlTYt7"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def clip_grads(grads, max_norm):\n",
        "    total_norm = 0\n",
        "    for grad in grads:\n",
        "        total_norm += np.sum(grad ** 2)\n",
        "    total_norm = np.sqrt(total_norm)\n",
        "\n",
        "    rate = max_norm / (total_norm + 1e-6)\n",
        "    if rate < 1:\n",
        "        for grad in grads:\n",
        "            grad *= rate"
      ],
      "metadata": {
        "id": "SURVbik8eSH1"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
        "        data_size = len(x)\n",
        "        max_iters = data_size // batch_size\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            # 뒤섞기\n",
        "            idx = np.random.permutation(np.arange(data_size))\n",
        "            x = x[idx]\n",
        "            t = t[idx]\n",
        "\n",
        "            for iters in range(max_iters):\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "                # 기울기 구해 매개변수 갱신\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                # 평가\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    avg_loss = total_loss / loss_count\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                    self.loss_list.append(float(avg_loss))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        x = np.arange(len(self.loss_list))\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('손실')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "class RnnlmTrainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.time_idx = None\n",
        "        self.ppl_list = None\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def get_batch(self, x, t, batch_size, time_size):\n",
        "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
        "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
        "\n",
        "        data_size = len(x)\n",
        "        jump = data_size // batch_size\n",
        "        offsets = [i * jump for i in range(batch_size)]  # 배치에서 각 샘플을 읽기 시작하는 위치\n",
        "\n",
        "        for time in range(time_size):\n",
        "            for i, offset in enumerate(offsets):\n",
        "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
        "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
        "            self.time_idx += 1\n",
        "        return batch_x, batch_t\n",
        "\n",
        "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
        "            max_grad=None, eval_interval=20):\n",
        "        data_size = len(xs)\n",
        "        max_iters = data_size // (batch_size * time_size)\n",
        "        self.time_idx = 0\n",
        "        self.ppl_list = []\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            for iters in range(max_iters):\n",
        "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
        "\n",
        "                # 기울기를 구해 매개변수 갱신\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                # 퍼플렉서티 평가\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    ppl = np.exp(total_loss / loss_count)\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 퍼플렉서티 %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
        "                    self.ppl_list.append(float(ppl))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        x = np.arange(len(self.ppl_list))\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "        plt.plot(x, self.ppl_list, label='train')\n",
        "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('퍼플렉서티')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def remove_duplicate(params, grads):\n",
        "    '''\n",
        "    매개변수 배열 중 중복되는 가중치를 하나로 모아\n",
        "    그 가중치에 대응하는 기울기를 더한다.\n",
        "    '''\n",
        "    params, grads = params[:], grads[:]  # copy list\n",
        "\n",
        "    while True:\n",
        "        find_flg = False\n",
        "        L = len(params)\n",
        "\n",
        "        for i in range(0, L - 1):\n",
        "            for j in range(i + 1, L):\n",
        "                # 가중치 공유 시\n",
        "                if params[i] is params[j]:\n",
        "                    grads[i] += grads[j]  # 경사를 더함\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "                    grads[i] += grads[j].T\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "\n",
        "                if find_flg: break\n",
        "            if find_flg: break\n",
        "\n",
        "        if not find_flg: break\n",
        "\n",
        "    return params, grads"
      ],
      "metadata": {
        "id": "OUKEBJWjdxl8"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "    '''\n",
        "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
        "    '''\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = [], []\n",
        "            for param in params:\n",
        "                self.m.append(np.zeros_like(param))\n",
        "                self.v.append(np.zeros_like(param))\n",
        "\n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
        "\n",
        "        for i in range(len(params)):\n",
        "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
        "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
        "\n",
        "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
      ],
      "metadata": {
        "id": "KJ5Ap42XeZZw"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size=1 #context=2\n",
        "hidden_size=5\n",
        "batch_size=3\n",
        "max_epoch=1000\n",
        "\n",
        "text='You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word=preprocess(text) #단어 사전과 숫자로 바뀐 text 가져오기\n",
        "\n",
        "vocab_size=len(word_to_id)\n",
        "contexts, target=create_contexts_target(corpus, window_size) #corpus의 contexts(주변 단어)와 target(해당 단어)을 설정\n",
        "target=convert_one_hot(target, vocab_size) #target을 원핫벡터로 변경\n",
        "contexts=convert_one_hot(contexts, vocab_size) #contexts를 원핫벡터로 변경\n",
        "\n",
        "model=SimpleCBOW(vocab_size, hidden_size) #model에 input size와 hiddensize 설정하여 입력\n",
        "optimizer=Adam() #최적화는 adam사용\n",
        "trainer=Trainer(model, optimizer) #모델 설정\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size) #모델 훈련\n",
        "trainer.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OOU-A1I8efi4",
        "outputId": "9476ae08-2704-4a4e-a44c-452799cd3067"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
            "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
            "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
            "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
            "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
            "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
            "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
            "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 454 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 455 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 456 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 457 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 458 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 459 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 460 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 461 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 462 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 463 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 464 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 465 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 466 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 467 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 468 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 469 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 470 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 471 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 472 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 473 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 474 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 475 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
            "| 에폭 476 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 477 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 478 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 479 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 480 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 481 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 482 |  반복 1 / 2 | 시간 1[s] | 손실 1.07\n",
            "| 에폭 483 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 484 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 485 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 486 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 487 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 488 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 489 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
            "| 에폭 490 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 491 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 492 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 493 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 494 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 495 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 496 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 497 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 498 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 499 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 500 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 501 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 502 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 503 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
            "| 에폭 504 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 505 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 506 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 507 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 508 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 509 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 510 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 511 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 512 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 513 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 514 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 515 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 516 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 517 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 518 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 519 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 520 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 521 |  반복 1 / 2 | 시간 1[s] | 손실 1.20\n",
            "| 에폭 522 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
            "| 에폭 523 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 524 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 525 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 526 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 527 |  반복 1 / 2 | 시간 1[s] | 손실 1.07\n",
            "| 에폭 528 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 529 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 530 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 531 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 532 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 533 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 534 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 535 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 536 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 537 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 538 |  반복 1 / 2 | 시간 1[s] | 손실 1.07\n",
            "| 에폭 539 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 540 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 541 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 542 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 543 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 544 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 545 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 546 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 547 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 548 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 549 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 550 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 551 |  반복 1 / 2 | 시간 1[s] | 손실 1.07\n",
            "| 에폭 552 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 553 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 554 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 555 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 556 |  반복 1 / 2 | 시간 1[s] | 손실 1.07\n",
            "| 에폭 557 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 558 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 559 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 560 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 561 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 562 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 563 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 564 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 565 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 566 |  반복 1 / 2 | 시간 1[s] | 손실 1.08\n",
            "| 에폭 567 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 568 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 569 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 570 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 571 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 572 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 573 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 574 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 575 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 576 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
            "| 에폭 577 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 578 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 579 |  반복 1 / 2 | 시간 1[s] | 손실 1.15\n",
            "| 에폭 580 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
            "| 에폭 581 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 582 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 583 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 584 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 585 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 586 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 587 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
            "| 에폭 588 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 589 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 590 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
            "| 에폭 591 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 592 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 593 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 594 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 595 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 596 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 597 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 598 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 599 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 600 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 601 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 602 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 603 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 604 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 605 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
            "| 에폭 606 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 607 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 608 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 609 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
            "| 에폭 610 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 611 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 612 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 613 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 614 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 615 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 616 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 617 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 618 |  반복 1 / 2 | 시간 1[s] | 손실 1.19\n",
            "| 에폭 619 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 620 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 621 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 622 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 623 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 624 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 625 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 626 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 627 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 628 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 629 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 630 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 631 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 632 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 633 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 634 |  반복 1 / 2 | 시간 1[s] | 손실 1.14\n",
            "| 에폭 635 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 636 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 637 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 638 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 639 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 640 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 641 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 642 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
            "| 에폭 643 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 644 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 645 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
            "| 에폭 646 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 647 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 648 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 649 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 650 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 651 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 652 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 653 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 654 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 655 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 656 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 657 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 658 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 659 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 660 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 661 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
            "| 에폭 662 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 663 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 664 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 665 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 666 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 667 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
            "| 에폭 668 |  반복 1 / 2 | 시간 1[s] | 손실 1.05\n",
            "| 에폭 669 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 670 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 671 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 672 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 673 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 674 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
            "| 에폭 675 |  반복 1 / 2 | 시간 1[s] | 손실 1.14\n",
            "| 에폭 676 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
            "| 에폭 677 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 678 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 679 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 680 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 681 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 682 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 683 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 684 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 685 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 686 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 687 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 688 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 689 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 690 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 691 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 692 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 693 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 694 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 695 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 696 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
            "| 에폭 697 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 698 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 699 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 700 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 701 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 702 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 703 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 704 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 705 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 706 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 707 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 708 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 709 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 710 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 711 |  반복 1 / 2 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 712 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 713 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 714 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
            "| 에폭 715 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 716 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 717 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 718 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
            "| 에폭 719 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 720 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 721 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 722 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 723 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 724 |  반복 1 / 2 | 시간 1[s] | 손실 1.18\n",
            "| 에폭 725 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
            "| 에폭 726 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 727 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 728 |  반복 1 / 2 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 729 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 730 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 731 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 732 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 733 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 734 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 735 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 736 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 737 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 738 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 739 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 740 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 741 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 742 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 743 |  반복 1 / 2 | 시간 1[s] | 손실 1.04\n",
            "| 에폭 744 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 745 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 746 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 747 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 748 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 749 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 750 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
            "| 에폭 751 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 752 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
            "| 에폭 753 |  반복 1 / 2 | 시간 1[s] | 손실 1.17\n",
            "| 에폭 754 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 755 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
            "| 에폭 756 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 757 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 758 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 759 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 760 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 761 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 762 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 763 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 764 |  반복 1 / 2 | 시간 1[s] | 손실 1.17\n",
            "| 에폭 765 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 766 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 767 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 768 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
            "| 에폭 769 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 770 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 771 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 772 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 773 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 774 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 775 |  반복 1 / 2 | 시간 1[s] | 손실 1.15\n",
            "| 에폭 776 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 777 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
            "| 에폭 778 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 779 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
            "| 에폭 780 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 781 |  반복 1 / 2 | 시간 1[s] | 손실 1.15\n",
            "| 에폭 782 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 783 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 784 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 785 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 786 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
            "| 에폭 787 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 788 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 789 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 790 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 791 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 792 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 793 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 794 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 795 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 796 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 797 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 798 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 799 |  반복 1 / 2 | 시간 1[s] | 손실 1.03\n",
            "| 에폭 800 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 801 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 802 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 803 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 804 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 805 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 806 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 807 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 808 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 809 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
            "| 에폭 810 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 811 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 812 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 813 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 814 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 815 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
            "| 에폭 816 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 817 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 818 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 819 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 820 |  반복 1 / 2 | 시간 1[s] | 손실 1.14\n",
            "| 에폭 821 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 822 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 823 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 824 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 825 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 826 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 827 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 828 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 829 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 830 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 831 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 832 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 833 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 834 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 835 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 836 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
            "| 에폭 837 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 838 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 839 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 840 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 841 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 842 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 843 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 844 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 845 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 846 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 847 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 848 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 849 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 850 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 851 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
            "| 에폭 852 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 853 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 854 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 855 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 856 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 857 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 858 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 859 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
            "| 에폭 860 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 861 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 862 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 863 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
            "| 에폭 864 |  반복 1 / 2 | 시간 1[s] | 손실 1.02\n",
            "| 에폭 865 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 866 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 867 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
            "| 에폭 868 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 869 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 870 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 871 |  반복 1 / 2 | 시간 1[s] | 손실 1.13\n",
            "| 에폭 872 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 873 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 874 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 875 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 876 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 877 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 878 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 879 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 880 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 881 |  반복 1 / 2 | 시간 1[s] | 손실 1.12\n",
            "| 에폭 882 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
            "| 에폭 883 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 884 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 885 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 886 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 887 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 888 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n",
            "| 에폭 889 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 890 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 891 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
            "| 에폭 892 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 893 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 894 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 895 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
            "| 에폭 896 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 897 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 898 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 899 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 900 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
            "| 에폭 901 |  반복 1 / 2 | 시간 1[s] | 손실 1.00\n",
            "| 에폭 902 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 903 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 904 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 905 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 906 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 907 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 908 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 909 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 910 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 911 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 912 |  반복 1 / 2 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 913 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 914 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 915 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 916 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 917 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 918 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 919 |  반복 1 / 2 | 시간 1[s] | 손실 0.91\n",
            "| 에폭 920 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 921 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 922 |  반복 1 / 2 | 시간 1[s] | 손실 1.11\n",
            "| 에폭 923 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 924 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 925 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
            "| 에폭 926 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 927 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 928 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 929 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 930 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 931 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 932 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
            "| 에폭 933 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 934 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 935 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 936 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 937 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 938 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 939 |  반복 1 / 2 | 시간 1[s] | 손실 1.09\n",
            "| 에폭 940 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 941 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
            "| 에폭 942 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 943 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 944 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 945 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 946 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
            "| 에폭 947 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 948 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 949 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 950 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 951 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 952 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
            "| 에폭 953 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 954 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 955 |  반복 1 / 2 | 시간 1[s] | 손실 1.13\n",
            "| 에폭 956 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 957 |  반복 1 / 2 | 시간 1[s] | 손실 0.98\n",
            "| 에폭 958 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 959 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
            "| 에폭 960 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
            "| 에폭 961 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 962 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 963 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
            "| 에폭 964 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
            "| 에폭 965 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 966 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 967 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 968 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
            "| 에폭 969 |  반복 1 / 2 | 시간 1[s] | 손실 1.11\n",
            "| 에폭 970 |  반복 1 / 2 | 시간 1[s] | 손실 0.81\n",
            "| 에폭 971 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 972 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
            "| 에폭 973 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
            "| 에폭 974 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 975 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 976 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 977 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 978 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 979 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
            "| 에폭 980 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 981 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 982 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
            "| 에폭 983 |  반복 1 / 2 | 시간 1[s] | 손실 1.10\n",
            "| 에폭 984 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 985 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
            "| 에폭 986 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 987 |  반복 1 / 2 | 시간 1[s] | 손실 0.99\n",
            "| 에폭 988 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 989 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
            "| 에폭 990 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 991 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
            "| 에폭 992 |  반복 1 / 2 | 시간 1[s] | 손실 0.96\n",
            "| 에폭 993 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
            "| 에폭 994 |  반복 1 / 2 | 시간 1[s] | 손실 0.95\n",
            "| 에폭 995 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
            "| 에폭 996 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 997 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
            "| 에폭 998 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 999 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
            "| 에폭 1000 |  반복 1 / 2 | 시간 1[s] | 손실 0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48152 (\\N{HANGUL SYLLABLE BAN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48373 (\\N{HANGUL SYLLABLE BOG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "  print(word, word_vecs[word_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s31qG-YfNLA",
        "outputId": "1063a8c7-013b-4179-d4db-47a4f9081423"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you [ 1.187929  -1.2200106  1.1589371 -1.1691171  1.1708155]\n",
            "say [-1.1900772  1.1894895 -1.1562139  1.0903571 -1.2027078]\n",
            "goodbye [ 0.72141814 -0.73722017  0.79706615 -0.7706305   0.7650157 ]\n",
            "and [-1.0974891  1.0314785 -1.2643914  1.5448523 -0.7393421]\n",
            "i [ 0.7299666  -0.7562159   0.8036245  -0.78025883  0.7869343 ]\n",
            "hello [ 1.1947032 -1.2059925  1.1600912 -1.183019   1.1716369]\n",
            ". [-0.895488    1.0164763  -0.5595875  -0.14111225 -1.3428044 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W=np.arange(21).reshape(7, 3)\n",
        "W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-xevepchGOs",
        "outputId": "d218f425-fd34-42e3-fddc-0252ad881989"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2],\n",
              "       [ 3,  4,  5],\n",
              "       [ 6,  7,  8],\n",
              "       [ 9, 10, 11],\n",
              "       [12, 13, 14],\n",
              "       [15, 16, 17],\n",
              "       [18, 19, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygP3CI1F8rJw",
        "outputId": "87570da0-c006-474d-e8e2-bc916e6c631e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=np.array([1, 0, 3, 0])\n",
        "W[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_lXyi3i8trv",
        "outputId": "c54cf8ad-2892-46bb-81d9-6e6aab097e06"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  4,  5],\n",
              "       [ 0,  1,  2],\n",
              "       [ 9, 10, 11],\n",
              "       [ 0,  1,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding:\n",
        "  def __init__(self, W):\n",
        "    self.params=[W]\n",
        "    self.grads=[np.zeros_like(W)]\n",
        "    self.idx=None\n",
        "\n",
        "  def forward(self, idx):\n",
        "    W, =self.params\n",
        "    self.idx=idx\n",
        "    out=W[idx]\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dW, = self.grads #기울기를 dW로 저장\n",
        "    dW[...]=0  #형태만 가져오므로 0으로 초기화\n",
        "    for i, word_id in enumerate(self.idx):\n",
        "      dW[word_id]+=dout[i] #중복될 경우에도 적용이 가능. 덮어쓰는 것이 아니라 더해줌\n",
        "      #np.add.at()\n",
        "    return None"
      ],
      "metadata": {
        "id": "UfAcJ0GZ8yC_"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingDot:\n",
        "  def __init__(self, W):\n",
        "    self.embed=Embedding(W)\n",
        "    self.params=self.embed.params\n",
        "    self.grads=self.embed.grads\n",
        "    self.cache=None\n",
        "\n",
        "  def forward(self, h, idx):\n",
        "    target_W=self.embed.forward(idx)\n",
        "    out=np.sum(target_W*h, axis=1)\n",
        "\n",
        "    self.cache=(h, target_W)\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    h, target_W=self.cache\n",
        "    dout=dout.reshape(dout.shape[0], 1)\n",
        "\n",
        "    dtarget_W=dout*h\n",
        "    self.embed.backward(dtarget_W)\n",
        "    dh=dout*target_W\n",
        "    return dh"
      ],
      "metadata": {
        "id": "X6r7Pf2l8_N_"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "r3Mnhk_AXNU1"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnigramSampler:\n",
        "    def __init__(self, corpus, power, sample_size):\n",
        "        self.sample_size = sample_size\n",
        "        self.vocab_size = None\n",
        "        self.word_p = None\n",
        "\n",
        "        counts = collections.Counter()\n",
        "        for word_id in corpus:\n",
        "            counts[word_id] += 1\n",
        "\n",
        "        vocab_size = len(counts)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.word_p = np.zeros(vocab_size)\n",
        "        for i in range(vocab_size):\n",
        "            self.word_p[i] = counts[i]\n",
        "\n",
        "        self.word_p = np.power(self.word_p, power)\n",
        "        self.word_p /= np.sum(self.word_p)\n",
        "\n",
        "    def get_negative_sample(self, target):\n",
        "        batch_size = target.shape[0]\n",
        "\n",
        "\n",
        "        negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            p = self.word_p.copy()\n",
        "            target_idx = target[i]\n",
        "            p[target_idx] = 0\n",
        "            p /= p.sum()\n",
        "            negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
        "\n",
        "\n",
        "        return negative_sample\n"
      ],
      "metadata": {
        "id": "oPWVcoL7Nh97"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = np.array([0, 1, 2, 3, 4, 1, 2, 3])\n",
        "power = 0.75\n",
        "sample_size = 2\n",
        "sampler = UnigramSampler(corpus, power, sample_size)\n",
        "target = np.array([1, 3, 0])\n",
        "negative_sample = sampler.get_negative_sample(target)\n",
        "print(negative_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IORyOQgnX0Z9",
        "outputId": "f460dab3-7ded-44cf-c816-f31b8ba03de1"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 2]\n",
            " [4 0]\n",
            " [2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.loss = None\n",
        "        self.y = None  # sigmoid의 출력\n",
        "        self.t = None  # 정답 데이터\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = 1 / (1 + np.exp(-x))\n",
        "\n",
        "        self.loss = cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = (self.y - self.t) * dout / batch_size\n",
        "        return dx"
      ],
      "metadata": {
        "id": "yq3kTs8ZYe_T"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NegativeSamplingLoss:\n",
        "    def __init__(self, W, corpus, power=0.75, sample_size=5):\n",
        "        self.sample_size = sample_size\n",
        "        self.sampler = UnigramSampler(corpus, power, sample_size)\n",
        "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size + 1)]\n",
        "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.embed_dot_layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def forward(self, h, target):\n",
        "        batch_size = target.shape[0]\n",
        "        negative_sample = self.sampler.get_negative_sample(target)\n",
        "\n",
        "        # 긍정적 예 순전파\n",
        "        score = self.embed_dot_layers[0].forward(h, target)\n",
        "        correct_label = np.ones(batch_size, dtype=np.int32)\n",
        "        loss = self.loss_layers[0].forward(score, correct_label)\n",
        "\n",
        "        # 부정적 예 순전파\n",
        "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
        "        for i in range(self.sample_size):\n",
        "            negative_target = negative_sample[:, i]\n",
        "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
        "            loss += self.loss_layers[1 + i].forward(score, negative_label)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dh = 0\n",
        "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
        "            dscore = l0.backward(dout)\n",
        "            dh += l1.backward(dscore)\n",
        "\n",
        "        return dh"
      ],
      "metadata": {
        "id": "zea1ha8nX2DX"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IN4GwkbTYSL4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}