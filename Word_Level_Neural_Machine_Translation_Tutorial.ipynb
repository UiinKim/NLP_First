{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9itE0gQuhnqFr9VcC7bov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UiinKim/UiinKim/blob/main/Word_Level_Neural_Machine_Translation_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV4Xl9nrlCkr",
        "outputId": "e6dd4c5f-a1b6-4812-da20-4ecf03556838"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OLvtfQ8cEQh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, Dense,GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "bEgFSJcLF0A6",
        "outputId": "14b46cb7-422b-4531-8166-7aea368d6512"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aad59a7d-efd3-4575-a7ee-1deabaed443a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aad59a7d-efd3-4575-a7ee-1deabaed443a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fra.txt to fra.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples=33000"
      ],
      "metadata": {
        "id": "GsD_BikwGbhA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "  #프랑스어의 악센트 삭제\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  sent=to_ascii(sent.lower())\n",
        "\n",
        "  #단어와 구두점 사이에 공백 추가\n",
        "  #i am a student. -> i am a student .\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  #(a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외하고 모두 공백으로 변환\n",
        "  sent=re.sub(r\"[^a-zA-Z!.?]+\", \" \", sent)\n",
        "\n",
        "  #다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent=re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "vfEK8Zj2JvuZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#전처리 테스트\n",
        "eng_sent=u\"Have you had dinner?\"\n",
        "fra_sent=u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print(\"전처리 전 영어 문장 : \", eng_sent)\n",
        "print(\"전처리 후 영어 문장 : \", preprocess_sentence(eng_sent))\n",
        "print(\"전처리 전 프랑스어 문장 : \", fra_sent)\n",
        "print(\"전처리 후 프랑스어 문장 : \", preprocess_sentence(fra_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wGr56HKLMIZ",
        "outputId": "704fdba6-7413-44c9-afe2-20313c77ec44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장 :  Have you had dinner?\n",
            "전처리 후 영어 문장 :  have you had dinner ?\n",
            "전처리 전 프랑스어 문장 :  Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장 :  avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.read_table('fra.txt')\n",
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HuPcAKIPiXL8",
        "outputId": "2a9c49c6-264e-41d0-df94-2a93dec2e045"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Go.        Va !  \\\n",
              "0  Go.     Marche.   \n",
              "1  Go.  En route !   \n",
              "2  Go.     Bouge !   \n",
              "3  Hi.     Salut !   \n",
              "4  Hi.      Salut.   \n",
              "\n",
              "  CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)  \n",
              "0  CC-BY 2.0 (France) Attribution: tatoeba.org #2...                               \n",
              "1  CC-BY 2.0 (France) Attribution: tatoeba.org #2...                               \n",
              "2  CC-BY 2.0 (France) Attribution: tatoeba.org #2...                               \n",
              "3  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                               \n",
              "4  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                               "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4ac04704-83f0-4165-bdad-524fba906b64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>Va !</th>\n",
              "      <th>CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #1158250 (Wittydev)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>En route !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ac04704-83f0-4165-bdad-524fba906b64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0a5a8059-cffd-4f46-a660-afe582f4f48d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a5a8059-cffd-4f46-a660-afe582f4f48d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0a5a8059-cffd-4f46-a660-afe582f4f48d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ac04704-83f0-4165-bdad-524fba906b64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ac04704-83f0-4165-bdad-524fba906b64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target=[],[],[]\n",
        "\n",
        "  with open(\"fra.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      src_line, tar_line, _=line.strip().split('\\t')\n",
        "\n",
        "      src_line=[w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      tar_line=preprocess_sentence(tar_line)\n",
        "      tar_line_in=[w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_out=[w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line)\n",
        "      decoder_input.append(tar_line_in)\n",
        "      decoder_target.append(tar_line_out)\n",
        "\n",
        "      if i==num_samples -1:\n",
        "        break\n",
        "        #최대치 넘어가면 멈추기\n",
        "  return encoder_input, decoder_input, decoder_target\n"
      ],
      "metadata": {
        "id": "58fV3wVoLkTv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out=load_preprocessed_data()\n",
        "print(\"인코더의 입력 : \", sents_en_in[:5])\n",
        "print('디코더의 입력 : ', sents_fra_in[:5])\n",
        "print(\"디코더의 레이블 : \", sents_fra_out[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKXyabsgjYFA",
        "outputId": "373526f3-6d56-4b73-eadb-1991bea4112b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력 :  [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "디코더의 입력 :  [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "디코더의 레이블 :  [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en=Tokenizer(filters=\"\",lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input=tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input=pad_sequences(encoder_input, padding='post')\n",
        "\n",
        "tokenizer_fra=Tokenizer(filters=\"\",lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "decoder_input=tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input=pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_target=tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target=pad_sequences(decoder_target, padding='post')"
      ],
      "metadata": {
        "id": "pHQ4Cvqxmy8e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코더의 입력의 크기 : ', encoder_input.shape)\n",
        "print(\"디코더의 입력의 크기 : \", decoder_input.shape)\n",
        "print(\"디코더의 레이블의 크기 : \", decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zAWf7_GoquM",
        "outputId": "d85e09f6-45aa-4986-e6d0-a0eb11d8d8f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더의 입력의 크기 :  (33000, 7)\n",
            "디코더의 입력의 크기 :  (33000, 16)\n",
            "디코더의 레이블의 크기 :  (33000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size=len(tokenizer_en.word_index)+1\n",
        "tar_vocab_size=len(tokenizer_fra.word_index)+1\n",
        "print(\"영어 집합의 크기 : \", src_vocab_size)\n",
        "print(\"프랑스어 집합의 크기 : \", tar_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo-U2Cikoqqg",
        "outputId": "bae95f75-9848-4555-eb41-c4653e158bec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 집합의 크기 :  4481\n",
            "프랑스어 집합의 크기 :  7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index=tokenizer_en.word_index\n",
        "index_to_src=tokenizer_en.index_word\n",
        "tar_to_index=tokenizer_fra.word_index\n",
        "index_to_tar=tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "xo5SDj28oqoP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터를 분리하기 위해 랜덤으로 섞어준다.\n",
        "indices=np.arange(encoder_input.shape[0]) #정수만 구하기 때문에shape[0]\n",
        "np.random.shuffle(indices)\n",
        "print('랜덤 시퀀스 : ', indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYvn2Zfzoqln",
        "outputId": "54d7b0e5-8103-4cee-c310-597ab0256a0e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시퀀스 :  [11770 19118  8046 ... 24996 32818 25037]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input=encoder_input[indices]\n",
        "decoder_input=decoder_input[indices]\n",
        "decoder_target=decoder_target[indices]"
      ],
      "metadata": {
        "id": "sewe3ojQp84h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xer4RFdHp80e",
        "outputId": "b1aad567-0217-4b4a-c9c0-401c3b1ae922"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2, 556,   3,  45,   1,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMh2K6cap8tE",
        "outputId": "b9313345-d546-4519-9845-eafbfe9e5e1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,    4,    9,   16, 2290,    1,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target[30997]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7XAowlSp8ff",
        "outputId": "410a5e69-1007-496b-a3d3-d5fd5803d041"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4,    9,   16, 2290,    1,    3,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증데이터\n",
        "n_of_val=int(33000*0.1)\n",
        "print(\"검증데이터의 수 : \", n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhrB1WthoqcG",
        "outputId": "e553753b-ef90-4452-ef58-d234ee141d77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증데이터의 수 :  3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train=encoder_input[:-n_of_val]\n",
        "decoder_input_train=decoder_input[:-n_of_val]\n",
        "decoder_target_train=decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test=encoder_input[-n_of_val:]\n",
        "decoder_input_test=decoder_input[-n_of_val:]\n",
        "decoder_target_test=decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "DXi6t549qyv9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7S_v4vbqytk",
        "outputId": "4f6790a6-6697-463c-cf4a-0c88ef6a7d29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 7)\n",
            "훈련 target 데이터의 크기 : (29700, 16)\n",
            "훈련 target 레이블의 크기 : (29700, 16)\n",
            "테스트 source 데이터의 크기 : (3300, 7)\n",
            "테스트 target 데이터의 크기 : (3300, 16)\n",
            "테스트 target 레이블의 크기 : (3300, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "T7GoXDVAqyrF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Masking은 패딩 토큰인 숫자 0의 경우 연산을 제외\n",
        "embedding_dim=64\n",
        "hidden_units=64"
      ],
      "metadata": {
        "id": "rGZm1TGKqyop"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#인코더\n",
        "encoder_inputs=Input(shape=(None,))\n",
        "enc_emb=Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
        "enc_masking=Masking(mask_value=0.0)(enc_emb)\n",
        "encoder_lstm=LSTM(hidden_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c=encoder_lstm(enc_masking)\n",
        "encoder_states=[state_h, state_c]"
      ],
      "metadata": {
        "id": "SM8CAOOmqyk6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#디코더\n",
        "decoder_inputs=Input(shape=(None,))\n",
        "dec_emb_layer=Embedding(tar_vocab_size, embedding_dim)#임베딩 층\n",
        "dec_emb=dec_emb_layer(decoder_inputs)# 밑에서 재사용하기 위해 분리시킴\n",
        "dec_masking=Masking(mask_value=0.0)(dec_emb)\n",
        "decoder_lstm=LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _=decoder_lstm(dec_masking, initial_state=encoder_states)\n",
        "decoder_dense=Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs=decoder_dense(decoder_outputs)#밑에서 재사용하기 위해 분리시킴"
      ],
      "metadata": {
        "id": "IiwUhmfLqyiM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  model=Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "  model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIDTz8pNjua4",
        "outputId": "ea08b18a-b0ef-4e41-e452-54938ad63dc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 31s 92ms/step - loss: 3.2858 - acc: 0.6150 - val_loss: 1.8770 - val_acc: 0.6434\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 9s 39ms/step - loss: 1.6966 - acc: 0.7275 - val_loss: 1.5260 - val_acc: 0.7720\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 9s 38ms/step - loss: 1.4117 - acc: 0.7862 - val_loss: 1.3291 - val_acc: 0.7983\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 1.2565 - acc: 0.8049 - val_loss: 1.2238 - val_acc: 0.8109\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 1.1561 - acc: 0.8149 - val_loss: 1.1506 - val_acc: 0.8176\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 1.0758 - acc: 0.8234 - val_loss: 1.0898 - val_acc: 0.8252\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 1.0051 - acc: 0.8321 - val_loss: 1.0379 - val_acc: 0.8322\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.9432 - acc: 0.8400 - val_loss: 0.9934 - val_acc: 0.8375\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 8s 35ms/step - loss: 0.8877 - acc: 0.8468 - val_loss: 0.9526 - val_acc: 0.8427\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.8372 - acc: 0.8525 - val_loss: 0.9200 - val_acc: 0.8477\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.7921 - acc: 0.8572 - val_loss: 0.8905 - val_acc: 0.8505\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.7502 - acc: 0.8620 - val_loss: 0.8623 - val_acc: 0.8538\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.7107 - acc: 0.8661 - val_loss: 0.8384 - val_acc: 0.8557\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.6746 - acc: 0.8704 - val_loss: 0.8166 - val_acc: 0.8578\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.6409 - acc: 0.8742 - val_loss: 0.7986 - val_acc: 0.8608\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.6086 - acc: 0.8782 - val_loss: 0.7829 - val_acc: 0.8618\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5792 - acc: 0.8819 - val_loss: 0.7660 - val_acc: 0.8632\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 8s 32ms/step - loss: 0.5518 - acc: 0.8860 - val_loss: 0.7540 - val_acc: 0.8649\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.5263 - acc: 0.8896 - val_loss: 0.7412 - val_acc: 0.8668\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.5025 - acc: 0.8930 - val_loss: 0.7336 - val_acc: 0.8682\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.4811 - acc: 0.8959 - val_loss: 0.7247 - val_acc: 0.8689\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4607 - acc: 0.8990 - val_loss: 0.7137 - val_acc: 0.8697\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.4406 - acc: 0.9025 - val_loss: 0.7079 - val_acc: 0.8708\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.4236 - acc: 0.9049 - val_loss: 0.7003 - val_acc: 0.8726\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.4048 - acc: 0.9082 - val_loss: 0.6951 - val_acc: 0.8731\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.3888 - acc: 0.9110 - val_loss: 0.6890 - val_acc: 0.8739\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3731 - acc: 0.9139 - val_loss: 0.6850 - val_acc: 0.8748\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3589 - acc: 0.9162 - val_loss: 0.6809 - val_acc: 0.8756\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.3458 - acc: 0.9186 - val_loss: 0.6766 - val_acc: 0.8759\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3329 - acc: 0.9206 - val_loss: 0.6753 - val_acc: 0.8763\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3209 - acc: 0.9230 - val_loss: 0.6719 - val_acc: 0.8772\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.3093 - acc: 0.9252 - val_loss: 0.6691 - val_acc: 0.8780\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.3000 - acc: 0.9271 - val_loss: 0.6680 - val_acc: 0.8789\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.2895 - acc: 0.9291 - val_loss: 0.6657 - val_acc: 0.8791\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.2797 - acc: 0.9313 - val_loss: 0.6667 - val_acc: 0.8793\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.2715 - acc: 0.9325 - val_loss: 0.6649 - val_acc: 0.8803\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.2634 - acc: 0.9342 - val_loss: 0.6641 - val_acc: 0.8804\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.2549 - acc: 0.9358 - val_loss: 0.6635 - val_acc: 0.8811\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.2478 - acc: 0.9371 - val_loss: 0.6647 - val_acc: 0.8809\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.2411 - acc: 0.9385 - val_loss: 0.6654 - val_acc: 0.8810\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.2343 - acc: 0.9397 - val_loss: 0.6657 - val_acc: 0.8813\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 8s 34ms/step - loss: 0.2277 - acc: 0.9409 - val_loss: 0.6662 - val_acc: 0.8812\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.2223 - acc: 0.9419 - val_loss: 0.6672 - val_acc: 0.8813\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.2170 - acc: 0.9427 - val_loss: 0.6667 - val_acc: 0.8816\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.2119 - acc: 0.9438 - val_loss: 0.6690 - val_acc: 0.8814\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 7s 29ms/step - loss: 0.2072 - acc: 0.9446 - val_loss: 0.6713 - val_acc: 0.8816\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 8s 33ms/step - loss: 0.2018 - acc: 0.9457 - val_loss: 0.6708 - val_acc: 0.8827\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 7s 31ms/step - loss: 0.1980 - acc: 0.9461 - val_loss: 0.6713 - val_acc: 0.8822\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 7s 30ms/step - loss: 0.1935 - acc: 0.9467 - val_loss: 0.6754 - val_acc: 0.8830\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 7s 32ms/step - loss: 0.1887 - acc: 0.9479 - val_loss: 0.6749 - val_acc: 0.8824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder의 테스트과정은 교사강요의 훈련과정과 동작 방식이 다르므로 모델을 다시 설계해야 한다.\n",
        "#encoder\n",
        "encoder_model=Model(encoder_inputs, encoder_states)\n",
        "\n",
        "#디코더 설계 시작\n",
        "decoder_state_input_h=Input(shape=(hidden_units,))\n",
        "decoder_state_input_c=Input(shape=(hidden_units,))\n",
        "decoder_state_inputs=[decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2=dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2=decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "decoder_states2=[state_h2, state_c2]\n",
        "\n",
        "#모든 시점에 대하여 단어 예측\n",
        "decoder_outputs2=decoder_dense(decoder_outputs2)\n",
        "\n",
        "#수정된 디코더\n",
        "decoder_model=Model([decoder_inputs]+decoder_state_inputs, [decoder_outputs2]+decoder_states2)"
      ],
      "metadata": {
        "id": "BznSNZVkuIiY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  #입력으로부터 인코더의 마지막 시점의 은닉상태, 셀상태를 얻는다.\n",
        "  states_value=encoder_model.predict(input_seq)\n",
        "\n",
        "  #<sos>에 해당하는 정수 생성\n",
        "  target_seq=np.zeros((1,1))\n",
        "  target_seq[0,0]=tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition=False\n",
        "  decoded_sentence=\"\"\n",
        "\n",
        "  #stop_condition=True까지 무한반복\n",
        "  while not stop_condition:\n",
        "    #states_value를 현 시점의 초기상태로 사용\n",
        "    output_tokens, h, c=decoder_model.predict([target_seq]+states_value)\n",
        "\n",
        "    #예측 결과를 단어로 변환\n",
        "    sampled_token_index=np.argmax(output_tokens[0,-1,:]) #softmax함수로 가장 큰 값을 배정\n",
        "    sampled_char=index_to_tar[sampled_token_index]\n",
        "\n",
        "    #현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence+=' '+sampled_char\n",
        "\n",
        "    #중단시점\n",
        "    if(sampled_char=='<eos>' or len(decoded_sentence)>50):\n",
        "      stop_condition=True\n",
        "\n",
        "    #현재 시점의 예측 결과를 다음 시점의 입력으로 사용\n",
        "    target_seq=np.zeros((1,1))\n",
        "    target_seq[0,0]=sampled_token_index #현재 시점의 예측 결과\n",
        "\n",
        "    states_value=[h,c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "metadata": {
        "id": "5SUyISjjyhp6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_src(input_seq):\n",
        "  sentence=''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word!=0):\n",
        "      sentence+=index_to_src[encoded_word]+' '\n",
        "  return sentence\n",
        "\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence=''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word!=0 and encoded_word!=tar_to_index['<sos>']and encoded_word!=tar_to_index['<eos>']):\n",
        "      sentence+=index_to_tar[encoded_word]+' '\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "VPNnjwq53TjY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [1, 70, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHp5qlWD41-o",
        "outputId": "404c4835-5efd-4c18-daf3-030f573acebc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "입력문장 : are they in love ? \n",
            "정답문장 : sont ils amoureux ? \n",
            "번역문장 : sont ils amoureux ? \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "입력문장 : he sang a song . \n",
            "정답문장 : il a chante une chanson . \n",
            "번역문장 : il a chante une chanson . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : i felt very happy . \n",
            "정답문장 : je me sentais tres heureux . \n",
            "번역문장 : je me suis sentie tres heureux . \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : do you have a copy ? \n",
            "정답문장 : en avez vous une copie ? \n",
            "번역문장 : en as tu un exemplaire ? \n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "입력문장 : i can protect you . \n",
            "정답문장 : je peux te proteger . \n",
            "번역문장 : je peux te proteger . \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyEY3wF-44DA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}